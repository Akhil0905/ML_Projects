
---

### âœ… `VisionModels(Inpainting)`

```markdown
# ğŸ–¼ï¸ VisionModels(Inpainting)

This project performs semantic image inpainting using Stable Diffusion. It includes segmentation-based masking and regenerating occluded regions of images to create realistic visuals.

---

## ğŸ¯ Objectives

- Generate masked regions using image segmentation
- Use Stable Diffusion inpainting pipeline for restoration
- Apply prompts for guided reconstruction

---

## ğŸ“Š Main packages used:
 - diffusers
 - torchvision
 - PIL
 - torch
 - transformers

**Note: This project runs best with GPU due to diffusion model complexity.**

---

## ğŸ§  Notes
 - Used sub-selectors to identify and mask objects
 - Supports text-guided inpainting with prompts
 - Image preprocessing and mask handling included

---

## ğŸ“ Folder Structure

```bash
VisionModels(Inpainting)/
â”œâ”€â”€ segmentImages.py         # Segmentation logic
â”œâ”€â”€ inpaint_pipeline.py      # Stable Diffusion inpainting
â”œâ”€â”€ sample_images/           # Input test cases
â”œâ”€â”€ outputs/                 # Inpainted image results
â””â”€â”€ README.md                # This file
