# ğŸ–¼ï¸ VisionModels(Inpainting)

This project performs semantic image inpainting using Stable Diffusion. It includes segmentation-based masking and regenerating occluded regions of images to create realistic visuals.

---

## ğŸ¯ Objectives

- Generate masked regions using image segmentation
- Use Stable Diffusion inpainting pipeline for restoration
- Apply prompts for guided reconstruction

---

## ğŸ“Š Main packages used:
 - diffusers
 - torchvision
 - PIL
 - torch
 - transformers

**Note: This project runs best with GPU due to diffusion model complexity.**

---

## ğŸ§  Notes
 - Used sub-selectors to identify and mask objects
 - Supports text-guided inpainting with prompts
 - Image preprocessing and mask handling included

---

## ğŸ“ Folder Structure

```bash
VisionModels(Inpainting)/
â”œâ”€â”€ subselectImages.ipynb           # Image Selection logic
â”œâ”€â”€ segmentImages.ipynb             # Generates Bird Masks
â”œâ”€â”€ removeBirds.ipynb               # Stable Diffusion inpainting
â”œâ”€â”€ replaceBirds.ipynb              # Inpainted new bird image
â”œâ”€â”€ substituteSquirrels.ipynb       # Inpainted squirrel images
â”œâ”€â”€ mySampleImages                  # Includes all the related images 
â””â”€â”€ README.md                       # This file
